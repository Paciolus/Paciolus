"""
Engagement ZIP Export — Sprint 101
Phase X: Engagement Layer

Generates a diagnostic package ZIP containing:
  - anomaly_summary.pdf — Anomaly summary report
  - workpaper_index.json — Workpaper index data
  - manifest.json — File list with SHA-256 hashes, timestamps, platform version

ZERO-STORAGE COMPLIANCE:
  - Does NOT include uploaded financial data
  - Does NOT include individual tool exports (user downloads separately)
  - Contains only metadata, narratives, and generated reports
"""

import json
import hashlib
from io import BytesIO
from datetime import datetime, UTC
from zipfile import ZipFile, ZIP_DEFLATED
from typing import Optional

from sqlalchemy.orm import Session

from models import Client
from engagement_model import Engagement
from anomaly_summary_generator import AnomalySummaryGenerator
from workpaper_index_generator import WorkpaperIndexGenerator
from follow_up_items_manager import FollowUpItemsManager
from follow_up_items_model import FollowUpItem
from version import __version__ as PLATFORM_VERSION


class EngagementExporter:
    """Generates a diagnostic package ZIP for an engagement."""

    def __init__(self, db: Session):
        self.db = db

    def _verify_engagement_access(
        self, user_id: int, engagement_id: int
    ) -> Optional[Engagement]:
        return (
            self.db.query(Engagement)
            .join(Client, Engagement.client_id == Client.id)
            .filter(
                Engagement.id == engagement_id,
                Client.user_id == user_id,
            )
            .first()
        )

    def _generate_comments_markdown(
        self, user_id: int, engagement_id: int
    ) -> Optional[bytes]:
        """Generate a markdown file of all follow-up item comment threads."""
        manager = FollowUpItemsManager(self.db)

        try:
            comments = manager.get_comments_for_engagement(user_id, engagement_id)
        except ValueError:
            return None

        if not comments:
            return None

        # Group comments by follow-up item
        items_map: dict[int, list] = {}
        for comment in comments:
            item_id = comment.follow_up_item_id
            if item_id not in items_map:
                items_map[item_id] = []
            items_map[item_id].append(comment)

        # Fetch item descriptions for context
        item_descriptions: dict[int, str] = {}
        for item_id in items_map:
            item = self.db.query(FollowUpItem).filter(FollowUpItem.id == item_id).first()
            if item:
                item_descriptions[item_id] = item.description

        lines = [
            "# Follow-Up Item Comments",
            "",
            "**DISCLAIMER:** This document is generated by Paciolus, a diagnostic intelligence tool.",
            "It does not constitute an audit opinion or professional assurance.",
            "",
            "---",
            "",
        ]

        for item_id, item_comments in sorted(items_map.items()):
            desc = item_descriptions.get(item_id, f"Follow-up item #{item_id}")
            lines.append(f"## Item #{item_id}: {desc}")
            lines.append("")

            # Separate top-level and replies
            top_level = [c for c in item_comments if c.parent_comment_id is None]
            replies_by_parent: dict[int, list] = {}
            for c in item_comments:
                if c.parent_comment_id is not None:
                    if c.parent_comment_id not in replies_by_parent:
                        replies_by_parent[c.parent_comment_id] = []
                    replies_by_parent[c.parent_comment_id].append(c)

            for comment in top_level:
                author = comment.author.name if comment.author else f"User {comment.user_id}"
                ts = comment.created_at.strftime("%Y-%m-%d %H:%M") if comment.created_at else ""
                lines.append(f"- **{author}** ({ts}): {comment.comment_text}")

                # Render replies (one level deep)
                for reply in replies_by_parent.get(comment.id, []):
                    r_author = reply.author.name if reply.author else f"User {reply.user_id}"
                    r_ts = reply.created_at.strftime("%Y-%m-%d %H:%M") if reply.created_at else ""
                    lines.append(f"  - **{r_author}** ({r_ts}): {reply.comment_text}")

            lines.append("")

        return "\n".join(lines).encode("utf-8")

    def generate_zip(self, user_id: int, engagement_id: int) -> tuple[bytes, str]:
        """
        Generate diagnostic package ZIP.

        Returns (zip_bytes, filename) tuple.
        """
        engagement = self._verify_engagement_access(user_id, engagement_id)
        if not engagement:
            raise ValueError("Engagement not found or access denied")

        client = self.db.query(Client).filter(Client.id == engagement.client_id).first()
        client_name = client.name if client else f"Client_{engagement.client_id}"

        # Generate component files
        summary_gen = AnomalySummaryGenerator(self.db)
        anomaly_pdf = summary_gen.generate_pdf(user_id, engagement_id)

        index_gen = WorkpaperIndexGenerator(self.db)
        index_data = index_gen.generate(user_id, engagement_id)
        index_json = json.dumps(index_data, indent=2, default=str).encode('utf-8')

        # Generate comment threads markdown
        comments_md = self._generate_comments_markdown(user_id, engagement_id)

        # Build manifest
        generated_at = datetime.now(UTC).isoformat()
        files = {
            "anomaly_summary.pdf": anomaly_pdf,
            "workpaper_index.json": index_json,
        }

        if comments_md:
            files["follow_up_comments.md"] = comments_md

        manifest = {
            "platform": "Paciolus",
            "version": PLATFORM_VERSION,
            "generated_at": generated_at,
            "engagement_id": engagement_id,
            "client_name": client_name,
            "period_start": engagement.period_start.isoformat() if engagement.period_start else "",
            "period_end": engagement.period_end.isoformat() if engagement.period_end else "",
            "files": [],
        }

        for filename, content in files.items():
            sha256 = hashlib.sha256(content).hexdigest()
            manifest["files"].append({
                "filename": filename,
                "size_bytes": len(content),
                "sha256": sha256,
            })

        manifest_json = json.dumps(manifest, indent=2).encode('utf-8')

        # Build ZIP
        zip_buffer = BytesIO()
        with ZipFile(zip_buffer, 'w', ZIP_DEFLATED) as zf:
            for filename, content in files.items():
                zf.writestr(filename, content)
            zf.writestr("manifest.json", manifest_json)

        zip_bytes = zip_buffer.getvalue()

        # Build download filename
        safe_client = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in client_name)
        safe_client = safe_client.strip().replace(' ', '_')
        period_end_str = engagement.period_end.strftime("%Y%m%d") if engagement.period_end else "unknown"
        download_filename = f"{safe_client}_{period_end_str}_diagnostic_package.zip"

        return zip_bytes, download_filename
